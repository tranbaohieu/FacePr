{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tranhieu/miniconda/envs/ocr/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from imageio import imread\n",
    "from scipy.spatial import distance\n",
    "import torch \n",
    "from torchvision import transforms\n",
    "from facenet_pytorch import InceptionResnetV1, fixed_image_standardization\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dlib\n",
    "from align import AlignDlib\n",
    "import glob\n",
    "import imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE MODELS\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "nn4_small2 = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    pretrained=\"casia-webface\"\n",
    ").to(device)\n",
    "\n",
    "nn4_small2.eval()\n",
    "\n",
    "alignment = AlignDlib('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image/ed_sheeran', 'image/adam_levine', 'image/me', 'image/adele', 'image/taylor_swift']\n",
      "                                               image  label        name\n",
      "0  image/ed_sheeran/Screenshot 2024-01-15 at 16.4...      0  ed_sheeran\n",
      "1  image/ed_sheeran/Screenshot 2024-01-15 at 16.3...      0  ed_sheeran\n",
      "2  image/ed_sheeran/ed-sheeran_glamour_16mar17_re...      0  ed_sheeran\n",
      "3  image/ed_sheeran/Screenshot 2024-01-15 at 16.4...      0  ed_sheeran\n",
      "4  image/ed_sheeran/Screenshot 2024-01-15 at 16.4...      0  ed_sheeran\n"
     ]
    }
   ],
   "source": [
    "#LOAD TRAINING INFORMATION\n",
    "train_paths = glob.glob(\"image/*\")\n",
    "print(train_paths)\n",
    "\n",
    "nb_classes = len(train_paths)\n",
    "\n",
    "df_train = pd.DataFrame(columns=['image', 'label', 'name'])\n",
    "\n",
    "for i,train_path in enumerate(train_paths):\n",
    "    name = os.path.basename(train_path)\n",
    "    images = glob.glob(train_path + \"/*\")\n",
    "    for image in images:\n",
    "        df_train.loc[len(df_train)]=[image,i,name]\n",
    "        \n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-PROCESSING\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def align_face(face):\n",
    "    (h,w,c) = face.shape\n",
    "    bb = dlib.rectangle(0, 0, w, h)\n",
    "    aligned_face = alignment.align(96, face, bb,landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "    return aligned_face\n",
    "  \n",
    "def load_and_align_images(filepaths):\n",
    "    aligned_images = []\n",
    "    for filepath in filepaths:\n",
    "        #print(filepath)\n",
    "        img = cv2.imread(filepath)\n",
    "        aligned = align_face(img)\n",
    "        aligned = (aligned / 255.).astype(np.float32)\n",
    "        aligned = aligned.transpose((2, 0, 1))\n",
    "        aligned = np.expand_dims(aligned, axis=0)\n",
    "        aligned_images.append(aligned)\n",
    "            \n",
    "    return np.array(aligned_images)\n",
    "    \n",
    "def calc_embs(filepaths, batch_size=2): \n",
    "    pd = []\n",
    "    for start in tqdm(range(0, len(filepaths), batch_size)):\n",
    "        aligned_images = load_and_align_images(filepaths[start:start+batch_size])\n",
    "        aligned_images = torch.from_numpy(aligned_images).squeeze(1)\n",
    "        emb = nn4_small2(aligned_images).detach().numpy()\n",
    "        pd.append(emb)\n",
    "    #embs = l2_normalize(np.concatenate(pd))\n",
    "    embs = np.concatenate(pd, axis=0)\n",
    "\n",
    "    return embs\n",
    "    \n",
    "def align_faces(faces):\n",
    "    aligned_images = []\n",
    "    for face in faces:\n",
    "        #print(face.shape)\n",
    "        aligned = align_face(face)\n",
    "        aligned = (aligned / 255.).astype(np.float32)\n",
    "        aligned = aligned.transpose((2, 0, 1))\n",
    "        aligned_images.append(aligned)\n",
    "        \n",
    "    return aligned_images\n",
    "\n",
    "def calc_emb_test(faces):\n",
    "    pd = []\n",
    "    aligned_faces = align_faces(faces)\n",
    "    aligned_faces = np.array(aligned_faces)\n",
    "    aligned_faces = torch.from_numpy(aligned_faces)\n",
    "    pd.append(nn4_small2(aligned_faces).detach().numpy())\n",
    "    #embs = l2_normalize(np.concatenate(pd))\n",
    "    embs = np.concatenate(pd, axis=0)\n",
    "    return np.array(embs)\n",
    "\n",
    "def trans(img):\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            fixed_image_standardization\n",
    "        ])\n",
    "    return transform(img)\n",
    "\n",
    "def fixed_image_standardization(image_tensor):\n",
    "    processed_tensor = (image_tensor - 127.5) / 128.0\n",
    "    return processed_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 655.48it/s]\n",
      " 93%|█████████▎| 13/14 [00:01<00:00,  9.84it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "100%|██████████| 14/14 [00:01<00:00,  8.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "label2idx = []\n",
    "\n",
    "for i in tqdm(range(len(train_paths))):\n",
    "    label2idx.append(np.asarray(df_train[df_train.label == i].index))\n",
    "\n",
    "train_embs = calc_embs(df_train.image)\n",
    "np.save(\"train_embs.npy\", train_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embs = np.load(\"train_embs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANALYSING\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "match_distances = []\n",
    "for i in range(nb_classes):\n",
    "    ids = label2idx[i]\n",
    "    distances = []\n",
    "    for j in range(len(ids) - 1):\n",
    "        for k in range(j + 1, len(ids)):\n",
    "            distances.append(distance.euclidean(train_embs[ids[j]].reshape(-1), train_embs[ids[k]].reshape(-1)))\n",
    "    match_distances.extend(distances)\n",
    "    \n",
    "unmatch_distances = []\n",
    "for i in range(nb_classes):\n",
    "    ids = label2idx[i]\n",
    "    distances = []\n",
    "    for j in range(10):\n",
    "        idx = np.random.randint(train_embs.shape[0])\n",
    "        while idx in label2idx[i]:\n",
    "            idx = np.random.randint(train_embs.shape[0])\n",
    "        distances.append(distance.euclidean(train_embs[ids[np.random.randint(len(ids))]].reshape(-1), train_embs[idx].reshape(-1)))\n",
    "    unmatch_distances.extend(distances)\n",
    "    \n",
    "_,_,_=plt.hist(match_distances,bins=100)\n",
    "_,_,_=plt.hist(unmatch_distances,bins=100,fc=(1, 0, 0, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(faces) = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g8/skpdfyzn41v7g2r7cy0fqs4r0000gn/T/ipykernel_94637/1687410674.py:44: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if p == \"unknown\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(faces) = 2\n",
      "len(faces) = 1\n",
      "len(faces) = 2\n",
      "len(faces) = 2\n",
      "len(faces) = 1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "test_paths = glob.glob(\"test_image/*.jpg\")\n",
    "for path in test_paths:\n",
    "    test_image = cv2.imread(path)\n",
    "    show_image = test_image.copy()\n",
    "\n",
    "    hogFaceDetector = dlib.get_frontal_face_detector()\n",
    "    faceRects = hogFaceDetector(test_image, 0)\n",
    "    \n",
    "    faces = []\n",
    "    \n",
    "    for faceRect in faceRects:\n",
    "        x1 = faceRect.left()\n",
    "        y1 = faceRect.top()\n",
    "        x2 = faceRect.right()\n",
    "        y2 = faceRect.bottom()\n",
    "        face = test_image[y1:y2,x1:x2]\n",
    "        \n",
    "        faces.append(face)\n",
    "\n",
    "    print(\"len(faces) = {0}\".format(len(faces)))\n",
    "    if(len(faces)==0):\n",
    "        print(\"no face detected!\")\n",
    "        continue\n",
    "    else:    \n",
    "        test_embs = calc_emb_test(faces)\n",
    "        \n",
    "    people = []\n",
    "    for i in range(test_embs.shape[0]):\n",
    "        distances = []\n",
    "        for j in range(len(train_paths)):\n",
    "            distances.append(np.min([distance.euclidean(test_embs[i].reshape(-1), train_embs[k].reshape(-1)) for k in label2idx[j]]))\n",
    "            #for k in label2idx[j]:\n",
    "                #print(distance.euclidean(test_embs[i].reshape(-1), train_embs[k].reshape(-1)))\n",
    "        if np.min(distances)>threshold:\n",
    "            people.append(\"unknown\")\n",
    "        else:\n",
    "            res = np.argsort(distances)[:1]\n",
    "            people.append(res)\n",
    "\n",
    "    names = []\n",
    "    title = \"\"\n",
    "    for p in people:\n",
    "        if p == \"unknown\":\n",
    "            name = \"unknown\"\n",
    "        else:\n",
    "            name = df_train[(df_train['label']==p[0])].name.iloc[0]\n",
    "            name = name.split(\"/\")[-1]\n",
    "        names.append(name)\n",
    "        title = title + name + \" \"\n",
    "        \n",
    "    for i,faceRect in enumerate(faceRects):\n",
    "        x1 = faceRect.left()\n",
    "        y1 = faceRect.top()\n",
    "        x2 = faceRect.right()\n",
    "        y2 = faceRect.bottom()\n",
    "        cv2.rectangle(show_image,(x1,y1),(x2,y2),(255,0,0),3)\n",
    "        cv2.putText(show_image,names[i],(x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,0,0),1,cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "    show_image = imutils.resize(show_image,width = 720)   \n",
    "    cv2.imshow(\"result\",show_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tranhieu/miniconda/envs/ocr/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "\n",
    "device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(thresholds= [0.7, 0.7, 0.8] ,keep_all=True, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: not authorized to capture video (status 0), requesting...\n",
      "OpenCV: camera failed to properly initialize!\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT,480)\n",
    "while cap.isOpened():\n",
    "    isSuccess, frame = cap.read()\n",
    "    if isSuccess:\n",
    "        boxes, _ = mtcnn.detect(frame)\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                bbox = list(map(int,box.tolist()))\n",
    "                frame = cv2.rectangle(frame,(bbox[0],bbox[1]),(bbox[2],bbox[3]),(0,0,255),6)\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    if cv2.waitKey(1)&0xFF == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
