{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tranhieu/miniconda/envs/ocr/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from imageio import imread\n",
    "from scipy.spatial import distance\n",
    "import torch \n",
    "from torchvision import transforms\n",
    "from facenet_pytorch import InceptionResnetV1, fixed_image_standardization\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dlib\n",
    "from align import AlignDlib\n",
    "import glob\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE MODELS\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "nn4_small2 = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    pretrained=\"casia-webface\"\n",
    ").to(device)\n",
    "\n",
    "nn4_small2.eval()\n",
    "\n",
    "alignment = AlignDlib('weights/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "mtcnn = MTCNN(thresholds= [0.7, 0.7, 0.8] ,keep_all=True, device = device)\n",
    "hogFaceDetector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image/ed_sheeran', 'image/adam_levine', 'image/me', 'image/adele', 'image/taylor_swift']\n",
      "                                               image  label        name\n",
      "0  image/ed_sheeran/Screenshot 2024-01-15 at 16.4...      0  ed_sheeran\n",
      "1  image/ed_sheeran/Screenshot 2024-01-15 at 16.3...      0  ed_sheeran\n",
      "2  image/ed_sheeran/ed-sheeran_glamour_16mar17_re...      0  ed_sheeran\n",
      "3  image/ed_sheeran/Screenshot 2024-01-15 at 16.4...      0  ed_sheeran\n",
      "4  image/ed_sheeran/Screenshot 2024-01-15 at 16.4...      0  ed_sheeran\n"
     ]
    }
   ],
   "source": [
    "#LOAD TRAINING INFORMATION\n",
    "train_paths = glob.glob(\"image/*\")\n",
    "print(train_paths)\n",
    "\n",
    "nb_classes = len(train_paths)\n",
    "\n",
    "df_train = pd.DataFrame(columns=['image', 'label', 'name'])\n",
    "\n",
    "for i,train_path in enumerate(train_paths):\n",
    "    name = os.path.basename(train_path)\n",
    "    images = glob.glob(train_path + \"/*\")\n",
    "    for image in images:\n",
    "        df_train.loc[len(df_train)]=[image,i,name]\n",
    "        \n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-PROCESSING\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def align_face(face):\n",
    "    (h,w,c) = face.shape\n",
    "    bb = dlib.rectangle(0, 0, w, h)\n",
    "    aligned_face, npLandmarks = alignment.align(96, face, bb,landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "    return aligned_face, npLandmarks\n",
    "  \n",
    "def load_and_align_images(filepaths):\n",
    "    aligned_images = []\n",
    "    for filepath in filepaths:\n",
    "        #print(filepath)\n",
    "        img = cv2.imread(filepath)\n",
    "        aligned, _ = align_face(img)\n",
    "        aligned = (aligned / 255.).astype(np.float32)\n",
    "        aligned = aligned.transpose((2, 0, 1))\n",
    "        aligned = np.expand_dims(aligned, axis=0)\n",
    "        aligned_images.append(aligned)\n",
    "            \n",
    "    return np.array(aligned_images)\n",
    "    \n",
    "def calc_embs(filepaths, batch_size=2): \n",
    "    pd = []\n",
    "    for start in tqdm(range(0, len(filepaths), batch_size)):\n",
    "        aligned_images = load_and_align_images(filepaths[start:start+batch_size])\n",
    "        aligned_images = torch.from_numpy(aligned_images).squeeze(1)\n",
    "        emb = nn4_small2(aligned_images).detach().numpy()\n",
    "        pd.append(emb)\n",
    "    #embs = l2_normalize(np.concatenate(pd))\n",
    "    embs = np.concatenate(pd, axis=0)\n",
    "\n",
    "    return embs\n",
    "    \n",
    "def align_faces(faces):\n",
    "    aligned_images = []\n",
    "    landmarks_of_face_list = []\n",
    "    for face in faces:\n",
    "        #print(face.shape)\n",
    "        aligned, npLandmarks = align_face(face)\n",
    "        aligned = (aligned / 255.).astype(np.float32)\n",
    "        aligned = aligned.transpose((2, 0, 1))\n",
    "        aligned_images.append(aligned)\n",
    "        landmarks_of_face_list.append(npLandmarks)\n",
    "        \n",
    "    return aligned_images, landmarks_of_face_list\n",
    "\n",
    "def calc_emb_test(faces):\n",
    "    pd = []\n",
    "    aligned_faces, landmarks_of_face_list = align_faces(faces)\n",
    "    aligned_faces = np.array(aligned_faces)\n",
    "    aligned_faces = torch.from_numpy(aligned_faces)\n",
    "    pd.append(nn4_small2(aligned_faces).detach().numpy())\n",
    "    #embs = l2_normalize(np.concatenate(pd))\n",
    "    embs = np.concatenate(pd, axis=0)\n",
    "    return np.array(embs), landmarks_of_face_list\n",
    "\n",
    "def trans(img):\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            fixed_image_standardization\n",
    "        ])\n",
    "    return transform(img)\n",
    "\n",
    "def fixed_image_standardization(image_tensor):\n",
    "    processed_tensor = (image_tensor - 127.5) / 128.0\n",
    "    return processed_tensor\n",
    "\n",
    "def mtcnn_detect(image):\n",
    "    boxes, _ = mtcnn.detect(image)\n",
    "    faces = []\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            bbox = list(map(int,box.tolist()))\n",
    "            faces.append(image[bbox[1] : bbox[3], bbox[0] : bbox[2]])\n",
    "    return boxes, faces\n",
    "\n",
    "def hog_svm_detect(image):\n",
    "    faceRects = hogFaceDetector(image, 0)\n",
    "    boxes = []\n",
    "    faces = []\n",
    "    \n",
    "    for faceRect in faceRects:\n",
    "        x1 = faceRect.left()\n",
    "        y1 = faceRect.top()\n",
    "        x2 = faceRect.right()\n",
    "        y2 = faceRect.bottom()\n",
    "        faces.append(image[y1 : y2, x1 : x2])\n",
    "        boxes.append(np.array([x1, y1, x2, y2]))\n",
    "    return boxes, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 732.94it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "label2idx = []\n",
    "\n",
    "for i in tqdm(range(len(train_paths))):\n",
    "    label2idx.append(np.asarray(df_train[df_train.label == i].index))\n",
    "\n",
    "train_embs = calc_embs(df_train.image)\n",
    "np.save(\"train_embs.npy\", train_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANALYSING\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "match_distances = []\n",
    "for i in range(nb_classes):\n",
    "    ids = label2idx[i]\n",
    "    distances = []\n",
    "    for j in range(len(ids) - 1):\n",
    "        for k in range(j + 1, len(ids)):\n",
    "            distances.append(distance.euclidean(train_embs[ids[j]].reshape(-1), train_embs[ids[k]].reshape(-1)))\n",
    "    match_distances.extend(distances)\n",
    "    \n",
    "unmatch_distances = []\n",
    "for i in range(nb_classes):\n",
    "    ids = label2idx[i]\n",
    "    distances = []\n",
    "    for j in range(10):\n",
    "        idx = np.random.randint(train_embs.shape[0])\n",
    "        while idx in label2idx[i]:\n",
    "            idx = np.random.randint(train_embs.shape[0])\n",
    "        distances.append(distance.euclidean(train_embs[ids[np.random.randint(len(ids))]].reshape(-1), train_embs[idx].reshape(-1)))\n",
    "    unmatch_distances.extend(distances)\n",
    "    \n",
    "_,_,_=plt.hist(match_distances,bins=100)\n",
    "_,_,_=plt.hist(unmatch_distances,bins=100,fc=(1, 0, 0, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedded vector\n",
    "train_embs = np.load(\"train_embs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(faces) = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g8/skpdfyzn41v7g2r7cy0fqs4r0000gn/T/ipykernel_29715/3321720386.py:41: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if p == \"unknown\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(faces) = 2\n",
      "len(faces) = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(faces) = 2\n",
      "len(faces) = 2\n",
      "len(faces) = 1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "test_paths = glob.glob(\"test_image/*.jpg\")\n",
    "for path in test_paths:\n",
    "    test_image = cv2.imread(path)\n",
    "    show_image = test_image.copy()\n",
    "    \n",
    "    faceRects = hogFaceDetector(test_image, 0)\n",
    "    \n",
    "    faces = []\n",
    "    \n",
    "    for faceRect in faceRects:\n",
    "        x1 = faceRect.left()\n",
    "        y1 = faceRect.top()\n",
    "        x2 = faceRect.right()\n",
    "        y2 = faceRect.bottom()\n",
    "        face = test_image[y1:y2,x1:x2]\n",
    "        \n",
    "        faces.append(face)\n",
    "\n",
    "    print(\"len(faces) = {0}\".format(len(faces)))\n",
    "    if(len(faces)==0):\n",
    "        print(\"no face detected!\")\n",
    "        continue\n",
    "    else:    \n",
    "        test_embs, _ = calc_emb_test(faces)\n",
    "        \n",
    "    people = []\n",
    "    for i in range(test_embs.shape[0]):\n",
    "        distances = []\n",
    "        for j in range(len(train_paths)):\n",
    "            distances.append(np.min([distance.euclidean(test_embs[i].reshape(-1), train_embs[k].reshape(-1)) for k in label2idx[j]]))\n",
    "        if np.min(distances)>threshold:\n",
    "            people.append(\"unknown\")\n",
    "        else:\n",
    "            res = np.argsort(distances)[:1]\n",
    "            people.append(res)\n",
    "\n",
    "    names = []\n",
    "    title = \"\"\n",
    "    for p in people:\n",
    "        if p == \"unknown\":\n",
    "            name = \"unknown\"\n",
    "        else:\n",
    "            name = df_train[(df_train['label']==p[0])].name.iloc[0]\n",
    "            name = name.split(\"/\")[-1]\n",
    "        names.append(name)\n",
    "        title = title + name + \" \"\n",
    "        \n",
    "    for i,faceRect in enumerate(faceRects):\n",
    "        x1 = faceRect.left()\n",
    "        y1 = faceRect.top()\n",
    "        x2 = faceRect.right()\n",
    "        y2 = faceRect.bottom()\n",
    "        cv2.rectangle(show_image,(x1,y1),(x2,y2),(255,0,0),3)\n",
    "        cv2.putText(show_image,names[i],(x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,0,0),2,cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "    show_image = imutils.resize(show_image,width = 720)   \n",
    "    cv2.imshow(\"result\",show_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
